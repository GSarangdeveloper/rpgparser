{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PpR6K4SYjOpW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the Excel file\n",
        "excel_file = pd.ExcelFile('excel.xlsx')\n",
        "\n",
        "# Get the sheets\n",
        "plan_details_df = pd.read_excel(excel_file, sheet_name='Plan Details')\n",
        "cost_shares_df = pd.read_excel(excel_file, sheet_name='Member Cost Share')\n",
        "\n",
        "# Print the sheet names to verify\n",
        "print(\"Sheet names:\", excel_file.sheet_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgaupayIjmyq",
        "outputId": "dd223e22-f2f3-4533-ce19-19dc5f49c1bc"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sheet names: ['Plan Details', 'Member Cost Share', 'Sheet1', 'Sheet3', 'Sheet2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGtPGs673apW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_plan_details(plan_details_df):\n",
        "    # Data is in row 5 (index 4)\n",
        "    data_row = plan_details_df.iloc[4]\n",
        "\n",
        "    # Create a dictionary with the extracted values\n",
        "    plan_details = {\n",
        "        'plan_id': data_row.iloc[0] if pd.notna(data_row.iloc[0]) else None,\n",
        "        'carrier': data_row.iloc[8] if pd.notna(data_row.iloc[8]) else None,\n",
        "        'formulary_id': data_row.iloc[9] if pd.notna(data_row.iloc[9]) else None,\n",
        "        'mail_max_days_supply': data_row.iloc[33] if pd.notna(data_row.iloc[33]) else None,\n",
        "        'retail_max_day_supply': data_row.iloc[38] if pd.notna(data_row.iloc[38]) else None,\n",
        "        'all_paper_max_days_supply': data_row.iloc[36] if pd.notna(data_row.iloc[36]) else None\n",
        "    }\n",
        "\n",
        "    return plan_details"
      ],
      "metadata": {
        "id": "k9xYOU6srTZr"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract plan details\n",
        "plan_details = extract_plan_details(plan_details_df)\n",
        "\n",
        "# Print the extracted plan details\n",
        "print(\"\\nPlan Details:\")\n",
        "for key, value in plan_details.items():\n",
        "    print(f\"  {key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79jdHx3GsVI1",
        "outputId": "fd99c3e8-00f5-400a-9582-153cf79a12ef"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Plan Details:\n",
            "  plan_id: 2162LWTP01\n",
            "  carrier: 2162\n",
            "  formulary_id: 1500\n",
            "  mail_max_days_supply: 90\n",
            "  retail_max_day_supply: 30\n",
            "  all_paper_max_days_supply: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "# Read the Excel file\n",
        "excel_file = pd.ExcelFile('excel.xlsx')\n",
        "\n",
        "# Get both sheets\n",
        "plan_details_df = pd.read_excel(excel_file, sheet_name='Plan Details')\n",
        "cost_shares_df = pd.read_excel(excel_file, sheet_name='Member Cost Share')\n",
        "\n",
        "# Function to extract Plan Details\n",
        "def extract_plan_details(plan_details_df):\n",
        "    # Data is in row 5 (index 4)\n",
        "    data_row = plan_details_df.iloc[4]\n",
        "\n",
        "    # Create a dictionary with the extracted values\n",
        "    plan_details = {\n",
        "        'plan_id': data_row.iloc[0] if pd.notna(data_row.iloc[0]) else None,\n",
        "        'carrier': data_row.iloc[8] if pd.notna(data_row.iloc[8]) else None,\n",
        "        'formulary_id': data_row.iloc[9] if pd.notna(data_row.iloc[9]) else None,\n",
        "        'mail_max_days_supply': data_row.iloc[33] if pd.notna(data_row.iloc[33]) else None,\n",
        "        'retail_max_day_supply': data_row.iloc[38] if pd.notna(data_row.iloc[38]) else None,\n",
        "        'all_paper_max_days_supply': data_row.iloc[36] if pd.notna(data_row.iloc[36]) else None\n",
        "    }\n",
        "\n",
        "    return plan_details\n",
        "\n",
        "# Function to extract Member Cost Shares using exact column names\n",
        "def extract_member_cost_shares(cost_shares_df):\n",
        "    # Column headings are in row 2 (index 1)\n",
        "    header_row = 1\n",
        "\n",
        "    # Get the column headers\n",
        "    headers = cost_shares_df.iloc[header_row].tolist()\n",
        "\n",
        "    # Define the exact column names we're looking for\n",
        "    column_names = {\n",
        "        'PlanID': 'planid',\n",
        "        'Pharmacy Network': 'pharmacy_network',\n",
        "        'Copay Category': 'copay_category',\n",
        "        'Delivery System': 'delivery_system',\n",
        "        'Copay Tier': 'copay_tier',\n",
        "        'Copay Max Days Supply': 'copay_max_days_supply',\n",
        "        'Copay Amount - Flat Dollar': 'copay_amount_flat',\n",
        "        'Copay Amount - Percent': 'copay_amount_percent',\n",
        "        'Copay Minimum': 'copay_minimum',\n",
        "        'Copay Maximum': 'copay_maximum',\n",
        "        'Copay Calculation': 'copay_calculation'\n",
        "    }\n",
        "\n",
        "    # Create a dictionary to store column indices\n",
        "    column_indices = {}\n",
        "\n",
        "    # Find the indices of the columns we need\n",
        "    for i, header in enumerate(headers):\n",
        "        if pd.notna(header) and isinstance(header, str):\n",
        "            # Check if this header matches any of our target column names\n",
        "            for target_name, field_name in column_names.items():\n",
        "                if target_name.lower() == header.lower():\n",
        "                    column_indices[field_name] = i\n",
        "                    print(f\"Found {target_name} at column index {i}\")\n",
        "\n",
        "    # Print which columns were not found\n",
        "    for target_name, field_name in column_names.items():\n",
        "        if field_name not in column_indices:\n",
        "            print(f\"Warning: Could not find column '{target_name}'\")\n",
        "\n",
        "    # Create a list to store the cost share items\n",
        "    cost_shares_list = []\n",
        "\n",
        "    # Data starts from row 4 (index 3)\n",
        "    for i in range(3, len(cost_shares_df)):\n",
        "        row = cost_shares_df.iloc[i]\n",
        "\n",
        "        # Skip empty rows\n",
        "        if all(pd.isna(x) for x in row):\n",
        "            continue\n",
        "\n",
        "        # Check if this row has \"Plan\" category\n",
        "        category_idx = column_indices.get('copay_category')\n",
        "        if category_idx is not None and category_idx < len(row):\n",
        "            category = row.iloc[category_idx]\n",
        "            if pd.notna(category) and isinstance(category, str) and category.strip() == \"Plan\":\n",
        "                # Create a dictionary for this row\n",
        "                cost_share_item = {}\n",
        "\n",
        "                # Extract values for each column\n",
        "                for field_name, idx in column_indices.items():\n",
        "                    if idx < len(row):\n",
        "                        cost_share_item[field_name] = row.iloc[idx]\n",
        "\n",
        "                # Add to the list\n",
        "                cost_shares_list.append(cost_share_item)\n",
        "\n",
        "                # Print the extracted values for debugging\n",
        "                print(f\"\\nExtracted data for row {i+1}:\")\n",
        "                for field_name, value in cost_share_item.items():\n",
        "                    print(f\"  {field_name}: {value}\")\n",
        "\n",
        "    return cost_shares_list\n",
        "\n",
        "# Function to apply special rules for Copay Max Days Supply\n",
        "def apply_max_days_supply_rules(cost_share_item, plan_details):\n",
        "    max_days_supply = cost_share_item.get('copay_max_days_supply')\n",
        "\n",
        "    # Check if max_days_supply is blank or '999'\n",
        "    if max_days_supply is None or pd.isna(max_days_supply) or str(max_days_supply).strip() == '' or str(max_days_supply).strip() == '999':\n",
        "        # Get the delivery system\n",
        "        delivery_system = cost_share_item.get('delivery_system', '')\n",
        "        if pd.isna(delivery_system):\n",
        "            delivery_system = ''\n",
        "        delivery_lower = str(delivery_system).lower()\n",
        "\n",
        "        # Apply rules based on channel\n",
        "        if 'mail' in delivery_lower:\n",
        "            cost_share_item['copay_max_days_supply'] = plan_details.get('mail_max_days_supply')\n",
        "            print(f\"Applied mail max days supply rule: {plan_details.get('mail_max_days_supply')}\")\n",
        "        elif 'paper' in delivery_lower:\n",
        "            paper_max = plan_details.get('all_paper_max_days_supply')\n",
        "            if paper_max and not pd.isna(paper_max):\n",
        "                cost_share_item['copay_max_days_supply'] = paper_max\n",
        "                print(f\"Applied paper max days supply rule: {paper_max}\")\n",
        "            else:\n",
        "                # If paper max not specified, use retail max\n",
        "                cost_share_item['copay_max_days_supply'] = plan_details.get('retail_max_day_supply')\n",
        "                print(f\"Applied retail max days supply rule (for paper): {plan_details.get('retail_max_day_supply')}\")\n",
        "        else:\n",
        "            # Default to retail max days supply\n",
        "            cost_share_item['copay_max_days_supply'] = plan_details.get('retail_max_day_supply')\n",
        "            print(f\"Applied retail max days supply rule: {plan_details.get('retail_max_day_supply')}\")\n",
        "\n",
        "# Extract plan details\n",
        "plan_details = extract_plan_details(plan_details_df)\n",
        "\n",
        "# Print the extracted plan details\n",
        "print(\"\\nPlan Details:\")\n",
        "for key, value in plan_details.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Extract member cost shares\n",
        "member_cost_shares = extract_member_cost_shares(cost_shares_df)\n",
        "\n",
        "# Print the number of records found\n",
        "print(f\"\\nFound {len(member_cost_shares)} Member Cost Share records with PLAN category\")\n",
        "\n",
        "# Apply the max days supply rule to each member cost share item\n",
        "print(\"\\nApplying Max Days Supply rules...\")\n",
        "for item in member_cost_shares:\n",
        "    apply_max_days_supply_rules(item, plan_details)\n",
        "\n",
        "# Print the updated member cost shares\n",
        "print(\"\\nMember Cost Shares after applying Max Days Supply rule:\")\n",
        "for i, item in enumerate(member_cost_shares):\n",
        "    print(f\"\\nItem {i+1}:\")\n",
        "    for key, value in item.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "# Save the results to a JSON file\n",
        "# Convert data to JSON-serializable format\n",
        "json_data = {\n",
        "    \"plan_details\": {k: str(v) for k, v in plan_details.items()},\n",
        "    \"member_cost_shares\": []\n",
        "}\n",
        "\n",
        "for item in member_cost_shares:\n",
        "    json_item = {}\n",
        "    for k, v in item.items():\n",
        "        json_item[k] = str(v) if pd.notna(v) else None\n",
        "    json_data[\"member_cost_shares\"].append(json_item)\n",
        "\n",
        "# Save to a JSON file\n",
        "with open('extracted_data.json', 'w') as f:\n",
        "    json.dump(json_data, f, indent=2)\n",
        "\n",
        "print(\"\\nData saved to extracted_data.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sED4RMCIucPE",
        "outputId": "0aef1caa-2178-492e-df1d-49cba7b92454"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Plan Details:\n",
            "  plan_id: 2162LWTP01\n",
            "  carrier: 2162\n",
            "  formulary_id: 1500\n",
            "  mail_max_days_supply: 90\n",
            "  retail_max_day_supply: 30\n",
            "  all_paper_max_days_supply: None\n",
            "Found PlanID at column index 0\n",
            "Found Copay Category at column index 1\n",
            "Found Pharmacy Network at column index 2\n",
            "Found Delivery System at column index 4\n",
            "Found Copay Tier at column index 5\n",
            "Found Copay Max Days Supply at column index 7\n",
            "Found Copay Amount - Flat Dollar at column index 8\n",
            "Found Copay Amount - Percent at column index 9\n",
            "Found Copay Minimum at column index 10\n",
            "Found Copay Maximum at column index 11\n",
            "Found Copay Calculation at column index 12\n",
            "\n",
            "Extracted data for row 12:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Mail\n",
            "  copay_tier: Preferred Brand - Tier 2\n",
            "  copay_max_days_supply: nan\n",
            "  copay_amount_flat: 62.5\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Extracted data for row 13:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Mail\n",
            "  copay_tier: Generic - Tier 1\n",
            "  copay_max_days_supply: nan\n",
            "  copay_amount_flat: 12.5\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Extracted data for row 29:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Retail/Paper-In\n",
            "  copay_tier: Non-Preferred Brand - Tier 3\n",
            "  copay_max_days_supply: nan\n",
            "  copay_amount_flat: 50\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Extracted data for row 31:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Retail/Paper-In\n",
            "  copay_tier: Preferred Brand - Tier 2\n",
            "  copay_max_days_supply: nan\n",
            "  copay_amount_flat: 25\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Extracted data for row 32:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Mail\n",
            "  copay_tier: Non-Preferred Brand - Tier 3\n",
            "  copay_max_days_supply: nan\n",
            "  copay_amount_flat: 125\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Extracted data for row 33:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Retail/Paper-In\n",
            "  copay_tier: Generic - Tier 1\n",
            "  copay_max_days_supply: nan\n",
            "  copay_amount_flat: 5\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Found 6 Member Cost Share records with PLAN category\n",
            "\n",
            "Applying Max Days Supply rules...\n",
            "Applied mail max days supply rule: 90\n",
            "Applied mail max days supply rule: 90\n",
            "Applied retail max days supply rule (for paper): 30\n",
            "Applied retail max days supply rule (for paper): 30\n",
            "Applied mail max days supply rule: 90\n",
            "Applied retail max days supply rule (for paper): 30\n",
            "\n",
            "Member Cost Shares after applying Max Days Supply rule:\n",
            "\n",
            "Item 1:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Mail\n",
            "  copay_tier: Preferred Brand - Tier 2\n",
            "  copay_max_days_supply: 90\n",
            "  copay_amount_flat: 62.5\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Item 2:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Mail\n",
            "  copay_tier: Generic - Tier 1\n",
            "  copay_max_days_supply: 90\n",
            "  copay_amount_flat: 12.5\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Item 3:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Retail/Paper-In\n",
            "  copay_tier: Non-Preferred Brand - Tier 3\n",
            "  copay_max_days_supply: 30\n",
            "  copay_amount_flat: 50\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Item 4:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Retail/Paper-In\n",
            "  copay_tier: Preferred Brand - Tier 2\n",
            "  copay_max_days_supply: 30\n",
            "  copay_amount_flat: 25\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Item 5:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Mail\n",
            "  copay_tier: Non-Preferred Brand - Tier 3\n",
            "  copay_max_days_supply: 90\n",
            "  copay_amount_flat: 125\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Item 6:\n",
            "  planid: 2162LWTP01\n",
            "  copay_category: Plan\n",
            "  pharmacy_network: nan\n",
            "  delivery_system: Retail/Paper-In\n",
            "  copay_tier: Generic - Tier 1\n",
            "  copay_max_days_supply: 30\n",
            "  copay_amount_flat: 5\n",
            "  copay_amount_percent: nan\n",
            "  copay_minimum: nan\n",
            "  copay_maximum: nan\n",
            "  copay_calculation: nan\n",
            "\n",
            "Data saved to extracted_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q google-generativeai\n",
        "\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Set your API key\n",
        "# You can get an API key from https://makersuite.google.com/app/apikey\n",
        "GOOGLE_API_KEY = \"YOUR_API_KEY_HERE\"  # Replace with your actual API key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "2FHSz1ds3hU_"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the rules JSON\n",
        "\n",
        "rules_json = {\n",
        "  \"functionality\": \"Member Cost Shares\",\n",
        "  \"description\": \"Rules for generating test cases based on Member Cost Share scenarios\",\n",
        "  \"scenario_types\": [\n",
        "    {\n",
        "      \"id\": \"flat_copay\",\n",
        "      \"name\": \"Flat Copay\",\n",
        "      \"conditions\": {\n",
        "        \"copay_category\": \"Plan\",\n",
        "        \"copay_amount_flat\": \"NOT_NULL\",\n",
        "        \"copay_amount_percent\": \"NULL\",\n",
        "        \"copay_minimum\": \"NULL\",\n",
        "        \"copay_maximum\": \"NULL\",\n",
        "        \"copay_calculation\": \"NULL\"\n",
        "      },\n",
        "      \"rules\": [\n",
        "        {\n",
        "          \"tier\": \"Generic - Tier 1\",\n",
        "          \"mony_codes\": [\n",
        "            \"Y\"\n",
        "          ],\n",
        "          \"repetitions\": 1\n",
        "        },\n",
        "        {\n",
        "          \"tier\": \"Preferred Brand - Tier 2\",\n",
        "          \"mony_codes\": [\n",
        "            \"N\",\n",
        "            \"O\"\n",
        "          ],\n",
        "          \"repetitions\": 2\n",
        "        },\n",
        "        {\n",
        "          \"tier\": \"Non-Preferred Brand - Tier 3\",\n",
        "          \"mony_codes\": [\n",
        "            \"N\",\n",
        "            \"O\"\n",
        "          ],\n",
        "          \"repetitions\": 2\n",
        "        }\n",
        "      ],\n",
        "      \"tier_mapping\": {\n",
        "        \"Generic - Tier 1\": {\"number\": \"1\", \"display_name\": \"Tier 1\"},\n",
        "        \"Preferred Brand - Tier 2\": {\"number\": \"2\", \"display_name\": \"Tier 2\"},\n",
        "        \"Non-Preferred Brand - Tier 3\": {\"number\": \"3\", \"display_name\": \"Tier 3\"}\n",
        "      },\n",
        "      \"channel_mapping\": {\n",
        "        \"Retail/Paper-In\": \"Retail\",\n",
        "        \"Mail\": \"Mail\"\n",
        "      },\n",
        "      \"testbed\": \"PP_Flat_Copay\",\n",
        "      \"scenario_template\": \"Copay Tier_{tier}_({mony_code})_{channel}_{max_days_supply} DS\",\n",
        "      \"verification_template\": \"Verify_${copay_amount_flat}- Flat Dollar Copay\",\n",
        "      \"output_format\": {\n",
        "        \"type\": \"markdown_table\",\n",
        "        \"columns\": [\"Testbed\", \"Scenario\", \"Verification\"],\n",
        "        \"separator\": \"|\"\n",
        "      },\n",
        "      \"processing_instructions\": {\n",
        "        \"tier_extraction\": \"Use 'number' from tier_mapping\",\n",
        "        \"channel_normalization\": \"Apply channel_mapping to delivery_system\",\n",
        "        \"scenario_generation\": \"For each matching cost share item, generate one scenario for each mony_code for that tier\"\n",
        "      }\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "# Save to a JSON file\n",
        "with open('rules.json', 'w') as f:\n",
        "    json.dump(rules_json, f, indent=2)\n",
        "\n",
        "print(\"\\nData saved to extracted_data.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMyq30ZS4lkv",
        "outputId": "9a88ec9b-0da6-46bf-fd03-a32133cfeca5"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data saved to extracted_data.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the JSON objects to strings for inclusion in the prompt\n",
        "with open('rules.json', 'r') as f:\n",
        "    rules_json_str = f.read()\n",
        "\n",
        "with open('extracted_data.json', 'r') as f:\n",
        "    extracted_data_str = f.read()\n",
        "\n",
        "# Create the prompt with the JSON data\n",
        "prompt = f\"\"\"\n",
        "Generate test case scenarios for pharmacy benefit plans based on the provided member cost share data and rules.\n",
        "\n",
        "# Rest of your template...\n",
        "\n",
        "Rules JSON:\n",
        "{rules_json_str}\n",
        "\n",
        "Extracted Data JSON:\n",
        "{extracted_data_str}\n",
        "\n",
        "Please generate the test case scenarios based on the above rules and data.\n",
        "\"\"\"\n",
        "\n",
        "# Validation checks\n",
        "def validate_json_in_prompt():\n",
        "    # 1. Check if both JSON strings are present in the prompt\n",
        "    if rules_json_str not in prompt:\n",
        "        print(\"WARNING: rules.json content is missing from the prompt!\")\n",
        "    else:\n",
        "        print(\"✓ rules.json content is included in the prompt\")\n",
        "\n",
        "    if extracted_data_str not in prompt:\n",
        "        print(\"WARNING: extracted_data.json content is missing from the prompt!\")\n",
        "    else:\n",
        "        print(\"✓ extracted_data.json content is included in the prompt\")\n",
        "\n",
        "    # 2. Optional: Check if the JSONs are valid\n",
        "    import json\n",
        "    try:\n",
        "        json.loads(rules_json_str)\n",
        "        print(\"✓ rules.json is valid JSON\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"WARNING: rules.json is not valid JSON!\")\n",
        "\n",
        "    try:\n",
        "        json.loads(extracted_data_str)\n",
        "        print(\"✓ extracted_data.json is valid JSON\")\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"WARNING: extracted_data.json is not valid JSON!\")\n",
        "\n",
        "    # 3. Optional: Print the first few characters of each JSON\n",
        "    print(\"\\nPreview of rules.json (first 100 chars):\")\n",
        "    print(rules_json_str[:100])\n",
        "\n",
        "    print(\"\\nPreview of extracted_data.json (first 100 chars):\")\n",
        "    print(extracted_data_str[:100])\n",
        "\n",
        "# Run validation\n",
        "validate_json_in_prompt()\n",
        "\n",
        "# Now you can use the prompt with confidence\n",
        "# api_call(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0Gwp2zS6jEZ",
        "outputId": "070200a9-f377-4e79-cda3-8e586fcb3b2c"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✓ rules.json content is included in the prompt\n",
            "✓ extracted_data.json content is included in the prompt\n",
            "✓ rules.json is valid JSON\n",
            "✓ extracted_data.json is valid JSON\n",
            "\n",
            "Preview of rules.json (first 100 chars):\n",
            "{\n",
            "  \"functionality\": \"Member Cost Shares\",\n",
            "  \"description\": \"Rules for generating test cases based o\n",
            "\n",
            "Preview of extracted_data.json (first 100 chars):\n",
            "{\n",
            "  \"plan_details\": {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"carrier\": \"2162\",\n",
            "    \"formulary_id\": \"1500\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-2.5-pro\",\n",
        "    generation_config={\n",
        "        \"temperature\": 0.0,  # Zero temperature for maximum determinism\n",
        "        \"top_p\": 1.0,\n",
        "        \"top_k\": 1,\n",
        "        \"seed\": 42,  # Fixed seed for reproducibility\n",
        "        \"max_output_tokens\": 8192,\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "gtrXZWbNGe2_"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    models = genai.list_models()\n",
        "    print(\"Available models:\")\n",
        "    for model in models:\n",
        "        print(f\"- {model.name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error listing models: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 850
        },
        "id": "qX34bQsyJAM3",
        "outputId": "393e4205-64f8-4ab5-e800-9fe18b286cdc"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available models:\n",
            "- models/chat-bison-001\n",
            "- models/text-bison-001\n",
            "- models/embedding-gecko-001\n",
            "- models/gemini-1.0-pro-vision-latest\n",
            "- models/gemini-pro-vision\n",
            "- models/gemini-1.5-pro-latest\n",
            "- models/gemini-1.5-pro-001\n",
            "- models/gemini-1.5-pro-002\n",
            "- models/gemini-1.5-pro\n",
            "- models/gemini-1.5-flash-latest\n",
            "- models/gemini-1.5-flash-001\n",
            "- models/gemini-1.5-flash-001-tuning\n",
            "- models/gemini-1.5-flash\n",
            "- models/gemini-1.5-flash-002\n",
            "- models/gemini-1.5-flash-8b\n",
            "- models/gemini-1.5-flash-8b-001\n",
            "- models/gemini-1.5-flash-8b-latest\n",
            "- models/gemini-1.5-flash-8b-exp-0827\n",
            "- models/gemini-1.5-flash-8b-exp-0924\n",
            "- models/gemini-2.5-pro-exp-03-25\n",
            "- models/gemini-2.5-pro-preview-03-25\n",
            "- models/gemini-2.0-flash-exp\n",
            "- models/gemini-2.0-flash\n",
            "- models/gemini-2.0-flash-001\n",
            "- models/gemini-2.0-flash-exp-image-generation\n",
            "- models/gemini-2.0-flash-lite-001\n",
            "- models/gemini-2.0-flash-lite\n",
            "- models/gemini-2.0-flash-lite-preview-02-05\n",
            "- models/gemini-2.0-flash-lite-preview\n",
            "- models/gemini-2.0-pro-exp\n",
            "- models/gemini-2.0-pro-exp-02-05\n",
            "- models/gemini-exp-1206\n",
            "- models/gemini-2.0-flash-thinking-exp-01-21\n",
            "- models/gemini-2.0-flash-thinking-exp\n",
            "- models/gemini-2.0-flash-thinking-exp-1219\n",
            "- models/learnlm-1.5-pro-experimental\n",
            "- models/gemma-3-1b-it\n",
            "- models/gemma-3-4b-it\n",
            "- models/gemma-3-12b-it\n",
            "- models/gemma-3-27b-it\n",
            "- models/embedding-001\n",
            "- models/text-embedding-004\n",
            "- models/gemini-embedding-exp-03-07\n",
            "- models/gemini-embedding-exp\n",
            "- models/aqa\n",
            "- models/imagen-3.0-generate-002\n",
            "- models/gemini-2.0-flash-live-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "import time\n",
        "\n",
        "GOOGLE_API_KEY = \"AIzaSyAsfLhl8LMG44OCx9jwCQDDxCKiwubc798\"  # Replace with your actual API key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "# Configure the model with settings for maximum consistency\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"models/gemini-2.0-pro-exp\",\n",
        "    generation_config={\n",
        "        \"temperature\": 0.0,  # Zero temperature for maximum determinism\n",
        "        \"top_p\": 1.0,\n",
        "        \"top_k\": 1,\n",
        "\n",
        "        \"max_output_tokens\": 8192,\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Read the JSON files directly\n",
        "with open('rules.json', 'r') as f:\n",
        "    rules_json_str = f.read()\n",
        "\n",
        "with open('extracted_data.json', 'r') as f:\n",
        "    extracted_data_str = f.read()\n",
        "\n",
        "# Use the latest Gemini model\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"models/gemini-1.5-pro-latest\",\n",
        "    generation_config={\n",
        "        \"temperature\": 0.0,  # Zero temperature for maximum determinism\n",
        "        \"top_p\": 1.0,\n",
        "        \"top_k\": 1,\n",
        "        \"max_output_tokens\": 8192,\n",
        "    }\n",
        ")\n",
        "\n",
        "# Create a prompt requesting a JSON output format\n",
        "prompt = f\"\"\"\n",
        "Generate pharmacy benefit plan test scenarios as JSON data using the provided rules and extracted data.\n",
        "\n",
        "Rules JSON:\n",
        "{rules_json_str}\n",
        "\n",
        "Extracted Data JSON:\n",
        "{extracted_data_str}\n",
        "\n",
        "Using the data above, generate test scenarios following these rules:\n",
        "1. Process each item in member_cost_shares where:\n",
        "   - copay_category is \"Plan\"\n",
        "   - copay_amount_flat is not null\n",
        "   - copay_amount_percent is null\n",
        "   - copay_minimum is null\n",
        "   - copay_maximum is null\n",
        "   - copay_calculation is null\n",
        "\n",
        "2. For each matching item:\n",
        "   - Plan ID: Use the \"planid\" field from the item\n",
        "   - Formulary ID: Use the \"formulary_id\" from plan_details\n",
        "   - Testbed: Always \"PP_Flat_Copay\"\n",
        "   - Scenario: Format as \"Copay Tier_X_(Y)_Channel_Days DS\"\n",
        "     - X: tier number (1 for Generic, 2 for Preferred Brand, 3 for Non-Preferred Brand)\n",
        "     - Y: MONY code (Y for Tier 1, N or O for Tiers 2 and 3)\n",
        "     - Channel: \"Mail\" or \"Retail\" (replace \"Retail/Paper-In\" with \"Retail\")\n",
        "     - Days: Use the \"copay_max_days_supply\" field\n",
        "   - Verification: Format as \"Verify_$Z- Flat Dollar Copay\"\n",
        "     - Z: Use the \"copay_amount_flat\" field\n",
        "\n",
        "3. Generate these scenarios:\n",
        "   - For \"Generic - Tier 1\": One scenario with MONY code = Y\n",
        "   - For \"Preferred Brand - Tier 2\": Two scenarios with MONY codes = N and O\n",
        "   - For \"Non-Preferred Brand - Tier 3\": Two scenarios with MONY codes = N and O\n",
        "\n",
        "Return ONLY a JSON array of scenario objects in exactly this format:\n",
        "[\n",
        "  {{\n",
        "    \"plan_id\": \"2162LWTP01\",\n",
        "    \"formulary_id\": \"None\",\n",
        "    \"testbed\": \"PP_Flat_Copay\",\n",
        "    \"scenario\": \"Copay Tier_2_(N)_Mail_90 DS\",\n",
        "    \"verification\": \"Verify_$62.5- Flat Dollar Copay\"\n",
        "  }},\n",
        "  {{\n",
        "    \"plan_id\": \"2162LWTP01\",\n",
        "    \"formulary_id\": \"None\",\n",
        "    \"testbed\": \"PP_Flat_Copay\",\n",
        "    \"scenario\": \"Copay Tier_2_(O)_Mail_90 DS\",\n",
        "    \"verification\": \"Verify_$62.5- Flat Dollar Copay\"\n",
        "  }},\n",
        "  ...\n",
        "]\n",
        "\n",
        "Your output must be ONLY the JSON array in the exact format shown above, with no other text.\n",
        "\"\"\"\n",
        "\n",
        "# Function to call Gemini with the prompt\n",
        "def call_gemini_with_prompt(prompt, retries=3, retry_delay=2):\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            response = model.generate_content(prompt)\n",
        "            return response.text\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt+1} failed: {e}\")\n",
        "            if attempt < retries - 1:\n",
        "                print(f\"Retrying in {retry_delay} seconds...\")\n",
        "                time.sleep(retry_delay)\n",
        "            else:\n",
        "                print(\"All retry attempts failed.\")\n",
        "                raise\n",
        "\n",
        "# Execute and display\n",
        "try:\n",
        "    result = call_gemini_with_prompt(prompt)\n",
        "\n",
        "    # Extract only the JSON part if there's any wrapping text\n",
        "    import re\n",
        "    json_match = re.search(r'\\[\\s*{.*}\\s*\\]', result, re.DOTALL)\n",
        "    if json_match:\n",
        "        result = json_match.group(0)\n",
        "\n",
        "    # Parse the JSON to validate it\n",
        "    scenarios = json.loads(result)\n",
        "\n",
        "    # Convert to a nicely formatted JSON string\n",
        "    formatted_json = json.dumps(scenarios, indent=2)\n",
        "    print(f\"Generated {len(scenarios)} scenarios successfully:\")\n",
        "    print(formatted_json)\n",
        "\n",
        "    # Save the JSON response to a file\n",
        "    with open('scenarios.json', 'w') as f:\n",
        "        f.write(formatted_json)\n",
        "    print(\"Scenarios saved to scenarios.json\")\n",
        "\n",
        "    # Convert to markdown table for display (optional)\n",
        "    table = \"| Plan ID | Formulary ID | Testbed | Scenario | Verification |\\n\"\n",
        "    table += \"| --- | --- | --- | --- | --- |\\n\"\n",
        "    for scenario in scenarios:\n",
        "        table += f\"| {scenario['plan_id']} | {scenario['formulary_id']} | {scenario['testbed']} | {scenario['scenario']} | {scenario['verification']} |\\n\"\n",
        "\n",
        "    # Save the markdown table\n",
        "    with open('scenarios_table.md', 'w') as f:\n",
        "        f.write(table)\n",
        "    print(\"Table format saved to scenarios_table.md\")\n",
        "\n",
        "    # Display the table\n",
        "    display(Markdown(table))\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Failed to get response: {e}\")\n",
        "    print(\"Raw response:\")\n",
        "    print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vqjIJ0CnSdwh",
        "outputId": "8ad33a2e-490f-4401-c919-c2d99a905fea"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 10 scenarios successfully:\n",
            "[\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_1_(Y)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$12.5- Flat Dollar Copay\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_2_(N)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$62.5- Flat Dollar Copay\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_2_(O)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$62.5- Flat Dollar Copay\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_3_(N)_Retail_30 DS\",\n",
            "    \"verification\": \"Verify_$50- Flat Dollar Copay\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_3_(O)_Retail_30 DS\",\n",
            "    \"verification\": \"Verify_$50- Flat Dollar Copay\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_2_(N)_Retail_30 DS\",\n",
            "    \"verification\": \"Verify_$25- Flat Dollar Copay\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_2_(O)_Retail_30 DS\",\n",
            "    \"verification\": \"Verify_$25- Flat Dollar Copay\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_3_(N)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$125- Flat Dollar Copay\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_3_(O)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$125- Flat Dollar Copay\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_1_(Y)_Retail_30 DS\",\n",
            "    \"verification\": \"Verify_$5- Flat Dollar Copay\"\n",
            "  }\n",
            "]\n",
            "Scenarios saved to scenarios.json\n",
            "Table format saved to scenarios_table.md\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Plan ID | Formulary ID | Testbed | Scenario | Verification |\n| --- | --- | --- | --- | --- |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_1_(Y)_Mail_90 DS | Verify_$12.5- Flat Dollar Copay |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_2_(N)_Mail_90 DS | Verify_$62.5- Flat Dollar Copay |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_2_(O)_Mail_90 DS | Verify_$62.5- Flat Dollar Copay |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_3_(N)_Retail_30 DS | Verify_$50- Flat Dollar Copay |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_3_(O)_Retail_30 DS | Verify_$50- Flat Dollar Copay |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_2_(N)_Retail_30 DS | Verify_$25- Flat Dollar Copay |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_2_(O)_Retail_30 DS | Verify_$25- Flat Dollar Copay |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_3_(N)_Mail_90 DS | Verify_$125- Flat Dollar Copay |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_3_(O)_Mail_90 DS | Verify_$125- Flat Dollar Copay |\n| 2162LWTP01 | 1500 | PP_Flat_Copay | Copay Tier_1_(Y)_Retail_30 DS | Verify_$5- Flat Dollar Copay |\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import os\n",
        "import json\n",
        "from IPython.display import display, Markdown\n",
        "import time\n",
        "\n",
        "# Set your API key\n",
        "GOOGLE_API_KEY = \"AIzaSyAsfLhl8LMG44OCx9jwCQDDxCKiwubc798\"  # Replace with your actual API key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "import json\n",
        "import re\n",
        "\n",
        "def update_scenarios_with_ndc(scenarios, formulary_data):\n",
        "    updated_scenarios = []\n",
        "\n",
        "    for scenario in scenarios:\n",
        "        # Extract tier and MONY from scenario field using regex\n",
        "        pattern = r'Copay Tier_(\\d+)_\\(([A-Z])\\)'\n",
        "        match = re.search(pattern, scenario['scenario'])\n",
        "\n",
        "        if not match:\n",
        "            print(f\"Could not parse tier and MONY from scenario: {scenario['scenario']}\")\n",
        "            scenario[\"ndc\"] = \"Could not parse tier and MONY\"\n",
        "            scenario[\"sql_query\"] = \"Could not generate SQL query\"\n",
        "            updated_scenarios.append(scenario)\n",
        "            continue  # Skip scenarios that can't be parsed\n",
        "\n",
        "        tier = match.group(1)\n",
        "        mony = match.group(2)\n",
        "\n",
        "        # Generate SQL query\n",
        "        sql_query = f\"SELECT NDC FROM formulary_data WHERE Formulary_ID = '{scenario['formulary_id']}' AND Tier = '{tier}' AND Multisource = '{mony}'\"\n",
        "        scenario[\"sql_query\"] = sql_query\n",
        "\n",
        "        # Find NDC based on query (simulating database lookup)\n",
        "        ndc = None\n",
        "        for row in formulary_data:\n",
        "            if row[0] == scenario['formulary_id'] and row[3] == tier and row[4] == mony:\n",
        "                ndc = row[2]\n",
        "                break  # Stop searching once a match is found\n",
        "\n",
        "        scenario[\"ndc\"] = ndc if ndc else \"No matching NDC found\"\n",
        "        updated_scenarios.append(scenario)\n",
        "\n",
        "    return updated_scenarios\n",
        "\n",
        "# Sample formulary data (replace with actual database connection)\n",
        "formulary_data = [\n",
        "    (\"1500\", \"123456778\", \"123456\", \"1\", \"Y\"),\n",
        "    (\"1500\", \"923456778\", \"623456\", \"2\", \"O\"),\n",
        "    (\"1500\", \"923456778\", \"34523456\", \"2\", \"N\"),\n",
        "    (\"1500\", \"923456778\", \"7823456\", \"3\", \"O\"),\n",
        "    (\"1500\", \"923456778\", \"564523456\", \"3\", \"N\")\n",
        "]\n",
        "\n",
        "# Load scenarios from JSON file or use the provided string\n",
        "try:\n",
        "    with open('scenarios.json', 'r') as f:\n",
        "        scenarios = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    # If file not found, use sample data\n",
        "    scenarios_json = \"\"\"[\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_1_(Y)_Mail_90 DS\",\n",
        "        \"verification\": \"Verify_$12.5- Flat Dollar Copay\"\n",
        "      },\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_2_(N)_Mail_90 DS\",\n",
        "        \"verification\": \"Verify_$62.5- Flat Dollar Copay\"\n",
        "      },\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_2_(O)_Mail_90 DS\",\n",
        "        \"verification\": \"Verify_$62.5- Flat Dollar Copay\"\n",
        "      },\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_3_(N)_Retail_30 DS\",\n",
        "        \"verification\": \"Verify_$50- Flat Dollar Copay\"\n",
        "      },\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_3_(O)_Retail_30 DS\",\n",
        "        \"verification\": \"Verify_$50- Flat Dollar Copay\"\n",
        "      },\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_2_(N)_Retail_30 DS\",\n",
        "        \"verification\": \"Verify_$25- Flat Dollar Copay\"\n",
        "      },\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_2_(O)_Retail_30 DS\",\n",
        "        \"verification\": \"Verify_$25- Flat Dollar Copay\"\n",
        "      },\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_3_(N)_Mail_90 DS\",\n",
        "        \"verification\": \"Verify_$125- Flat Dollar Copay\"\n",
        "      },\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_3_(O)_Mail_90 DS\",\n",
        "        \"verification\": \"Verify_$125- Flat Dollar Copay\"\n",
        "      },\n",
        "      {\n",
        "        \"plan_id\": \"2162LWTP01\",\n",
        "        \"formulary_id\": \"1500\",\n",
        "        \"testbed\": \"PP_Flat_Copay\",\n",
        "        \"scenario\": \"Copay Tier_1_(Y)_Retail_30 DS\",\n",
        "        \"verification\": \"Verify_$5- Flat Dollar Copay\"\n",
        "      }\n",
        "    ]\"\"\"\n",
        "    scenarios = json.loads(scenarios_json)\n",
        "\n",
        "# Update scenarios and print the result\n",
        "updated_scenarios = update_scenarios_with_ndc(scenarios, formulary_data)\n",
        "\n",
        "# Print first 2 scenarios for brevity\n",
        "print(json.dumps(updated_scenarios[:2], indent=2))\n",
        "\n",
        "# Save to file\n",
        "with open('scenarios_with_ndc.json', 'w') as f:\n",
        "    json.dump(updated_scenarios, f, indent=2)\n",
        "print(\"Updated scenarios saved to scenarios_with_ndc.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su0aLRy6qGuL",
        "outputId": "3f3be968-b1c8-4899-c410-b72529299dcf"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_1_(Y)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$12.5- Flat Dollar Copay\",\n",
            "    \"sql_query\": \"SELECT NDC FROM formulary_data WHERE Formulary_ID = '1500' AND Tier = '1' AND Multisource = 'Y'\",\n",
            "    \"ndc\": \"123456\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_2_(N)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$62.5- Flat Dollar Copay\",\n",
            "    \"sql_query\": \"SELECT NDC FROM formulary_data WHERE Formulary_ID = '1500' AND Tier = '2' AND Multisource = 'N'\",\n",
            "    \"ndc\": \"34523456\"\n",
            "  }\n",
            "]\n",
            "Updated scenarios saved to scenarios_with_ndc.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "\n",
        "# Set your API key\n",
        "API_KEY = \"AIzaSyAsfLhl8LMG44OCx9jwCQDDxCKiwubc798\"   # Replace with your actual API key\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# Define database schema for the LLM\n",
        "formulary_schema = \"\"\"\n",
        "Table: formulary_data\n",
        "Columns:\n",
        "- Formulary_ID (text) - The unique identifier for the formulary\n",
        "- GPI (text) - Generic Product Identifier\n",
        "- NDC (text) - National Drug Code, the identifier we want to retrieve\n",
        "- Tier (text) - Numeric tier level (1, 2, or 3)\n",
        "- Multisource (text) - MONY code (Y, N, or O)\n",
        "\n",
        "Sample data:\n",
        "(1500, 123456778, 123456, 1, Y)\n",
        "(1500, 923456778, 623456, 2, O)\n",
        "(1500, 923456778, 34523456, 2, N)\n",
        "(1500, 923456778, 7823456, 3, O)\n",
        "(1500, 923456778, 564523456, 3, N)\n",
        "\"\"\"\n",
        "\n",
        "# Load scenarios from JSON file\n",
        "try:\n",
        "    with open('scenarios.json', 'r') as f:\n",
        "        scenarios = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: scenarios.json file not found. Please run Phase 1 first.\")\n",
        "    exit(1)\n",
        "\n",
        "# Create a model instance\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"models/gemini-1.5-pro-latest\",  # Use an appropriate model\n",
        "    generation_config={\n",
        "        \"temperature\": 0.0,  # Zero temperature for deterministic output\n",
        "        \"top_p\": 1.0,\n",
        "        \"top_k\": 1,\n",
        "        \"max_output_tokens\": 8192,\n",
        "    }\n",
        ")\n",
        "\n",
        "def generate_sql_for_scenarios(scenarios, db_schema):\n",
        "    \"\"\"Use the LLM to generate SQL queries for each scenario\"\"\"\n",
        "\n",
        "    # First, let's create a prompt that explains what we want to do\n",
        "    base_prompt = f\"\"\"\n",
        "You are a SQL query generator for pharmacy benefit test scenarios.\n",
        "\n",
        "DATABASE SCHEMA:\n",
        "{db_schema}\n",
        "\n",
        "For each test scenario that follows this pattern:\n",
        "\"Copay Tier_X_(Y)_Channel_Z DS\"\n",
        "\n",
        "Where:\n",
        "- X is the tier number (1, 2, or 3)\n",
        "- Y is the MONY code (Y, N, or O)\n",
        "- Channel and Z are not relevant for the query\n",
        "\n",
        "Generate a SQL query that will find the matching NDC in the formulary_data table.\n",
        "The query should check for:\n",
        "1. The Formulary_ID matching the scenario's formulary_id field\n",
        "2. The Tier matching the tier number extracted from the scenario pattern\n",
        "3. The Multisource matching the MONY code extracted from the scenario pattern\n",
        "\n",
        "For example, if the scenario is \"Copay Tier_2_(N)_Mail_90 DS\" with formulary_id \"1500\",\n",
        "the SQL would be:\n",
        "SELECT NDC FROM formulary_data WHERE Formulary_ID = '1500' AND Tier = '2' AND Multisource = 'N'\n",
        "\n",
        "DO NOT include any explanation, just return the exact SQL query.\n",
        "\"\"\"\n",
        "\n",
        "    updated_scenarios = []\n",
        "\n",
        "    # Process each scenario with the LLM\n",
        "    for scenario in scenarios:\n",
        "        # Extract relevant information for the prompt\n",
        "        scenario_string = scenario['scenario']\n",
        "        formulary_id = scenario['formulary_id']\n",
        "\n",
        "        # Create a specific prompt for this scenario\n",
        "        specific_prompt = f\"{base_prompt}\\n\\nScenario: {scenario_string}\\nFormulary ID: {formulary_id}\\n\\nSQL query:\"\n",
        "\n",
        "        # Call the LLM\n",
        "        try:\n",
        "            response = model.generate_content(specific_prompt)\n",
        "            sql_query = response.text.strip()\n",
        "\n",
        "            # As a backup, use regex to extract in case the LLM doesn't cooperate\n",
        "            if not sql_query.upper().startswith(\"SELECT\"):\n",
        "                pattern = r'Copay Tier_(\\d+)_\\(([A-Z])\\)'\n",
        "                match = re.search(pattern, scenario_string)\n",
        "                if match:\n",
        "                    tier = match.group(1)\n",
        "                    mony = match.group(2)\n",
        "                    sql_query = f\"SELECT NDC FROM formulary_data WHERE Formulary_ID = '{formulary_id}' AND Tier = '{tier}' AND Multisource = '{mony}'\"\n",
        "                else:\n",
        "                    sql_query = \"Error: Could not generate SQL query\"\n",
        "\n",
        "            # Add the SQL query to the scenario\n",
        "            scenario[\"sql_query\"] = sql_query\n",
        "\n",
        "            # Now look up the appropriate NDC using the SQL query\n",
        "            # (For simplicity, we'll simulate this lookup with the sample data)\n",
        "\n",
        "            # Use regex to extract parameters from the generated SQL\n",
        "            formulary_match = re.search(r\"Formulary_ID\\s*=\\s*'([^']+)'\", sql_query)\n",
        "            tier_match = re.search(r\"Tier\\s*=\\s*'([^']+)'\", sql_query)\n",
        "            multisource_match = re.search(r\"Multisource\\s*=\\s*'([^']+)'\", sql_query)\n",
        "\n",
        "            if formulary_match and tier_match and multisource_match:\n",
        "                # Extract the parameters\n",
        "                sql_formulary_id = formulary_match.group(1)\n",
        "                sql_tier = tier_match.group(1)\n",
        "                sql_multisource = multisource_match.group(1)\n",
        "\n",
        "                # Simulate database lookup with your sample data\n",
        "                formulary_data = [\n",
        "                    (\"1500\", \"123456778\", \"123456\", \"1\", \"Y\"),\n",
        "                    (\"1500\", \"923456778\", \"623456\", \"2\", \"O\"),\n",
        "                    (\"1500\", \"923456778\", \"34523456\", \"2\", \"N\"),\n",
        "                    (\"1500\", \"923456778\", \"7823456\", \"3\", \"O\"),\n",
        "                    (\"1500\", \"923456778\", \"564523456\", \"3\", \"N\")\n",
        "                ]\n",
        "\n",
        "                # Find matching NDC\n",
        "                ndc = None\n",
        "                for row in formulary_data:\n",
        "                    if (row[0] == sql_formulary_id and\n",
        "                        row[3] == sql_tier and\n",
        "                        row[4] == sql_multisource):\n",
        "                        ndc = row[2]\n",
        "                        break\n",
        "\n",
        "                scenario[\"ndc\"] = ndc if ndc else \"No matching NDC found\"\n",
        "            else:\n",
        "                scenario[\"ndc\"] = \"Error: Could not parse SQL parameters\"\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating SQL for scenario '{scenario_string}': {e}\")\n",
        "            scenario[\"sql_query\"] = f\"Error: {str(e)}\"\n",
        "            scenario[\"ndc\"] = \"Error during generation\"\n",
        "\n",
        "        updated_scenarios.append(scenario)\n",
        "\n",
        "    return updated_scenarios\n",
        "\n",
        "# Generate SQL for all scenarios\n",
        "enriched_scenarios = generate_sql_for_scenarios(scenarios, formulary_schema)\n",
        "\n",
        "# Print first 2 scenarios for brevity\n",
        "print(json.dumps(enriched_scenarios[:2], indent=2))\n",
        "\n",
        "# Save to file\n",
        "with open('scenarios_with_ndc.json', 'w') as f:\n",
        "    json.dump(enriched_scenarios, f, indent=2)\n",
        "print(\"Updated scenarios saved to scenarios_with_ndc.json\")\n",
        "\n",
        "# In a real-world implementation, you would replace the sample data lookup\n",
        "# with an actual database connection, for example:\n",
        "\n",
        "\"\"\"\n",
        "# Example with a real database connection\n",
        "import sqlite3\n",
        "\n",
        "def find_ndc_with_real_db(sql_query):\n",
        "    conn = sqlite3.connect('formulary.db')\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        cursor.execute(sql_query)\n",
        "        result = cursor.fetchone()\n",
        "        if result:\n",
        "            return result[0]  # Return the NDC\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Database error: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        conn.close()\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "YOQ7yPf4us9g",
        "outputId": "4a3b50ff-f853-49d5-a186-4fac6cbc90d5"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 102.33ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 131.03ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating SQL for scenario 'Copay Tier_3_(O)_Retail_30 DS': 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error generating SQL for scenario 'Copay Tier_2_(N)_Retail_30 DS': 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 128.99ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 153.47ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating SQL for scenario 'Copay Tier_2_(O)_Retail_30 DS': 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error generating SQL for scenario 'Copay Tier_3_(N)_Mail_90 DS': 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 127.94ms\n",
            "WARNING:tornado.access:429 POST /v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 102.88ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error generating SQL for scenario 'Copay Tier_3_(O)_Mail_90 DS': 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "Error generating SQL for scenario 'Copay Tier_1_(Y)_Retail_30 DS': 429 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-pro-latest:generateContent?%24alt=json%3Benum-encoding%3Dint: You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits.\n",
            "[\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_1_(Y)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$12.5- Flat Dollar Copay\",\n",
            "    \"sql_query\": \"SELECT NDC FROM formulary_data WHERE Formulary_ID = '1500' AND Tier = '1' AND Multisource = 'Y'\",\n",
            "    \"ndc\": \"123456\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_2_(N)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$62.5- Flat Dollar Copay\",\n",
            "    \"sql_query\": \"SELECT NDC FROM formulary_data WHERE Formulary_ID = '1500' AND Tier = '2' AND Multisource = 'N'\",\n",
            "    \"ndc\": \"34523456\"\n",
            "  }\n",
            "]\n",
            "Updated scenarios saved to scenarios_with_ndc.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Example with a real database connection\\nimport sqlite3\\n\\ndef find_ndc_with_real_db(sql_query):\\n    conn = sqlite3.connect(\\'formulary.db\\')\\n    cursor = conn.cursor()\\n    try:\\n        cursor.execute(sql_query)\\n        result = cursor.fetchone()\\n        if result:\\n            return result[0]  # Return the NDC\\n        else:\\n            return None\\n    except Exception as e:\\n        print(f\"Database error: {e}\")\\n        return None\\n    finally:\\n        conn.close()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Set your API key\n",
        "API_KEY = \"AIzaSyAsfLhl8LMG44OCx9jwCQDDxCKiwubc798\"\n",
        "genai.configure(api_key=API_KEY)\n",
        "\n",
        "# Define database schema for the LLM\n",
        "formulary_schema = \"\"\"\n",
        "Table: formulary_data\n",
        "Columns:\n",
        "- Formulary_ID (text) - The unique identifier for the formulary\n",
        "- GPI (text) - Generic Product Identifier\n",
        "- NDC (text) - National Drug Code, the identifier we want to retrieve\n",
        "- Tier (text) - Numeric tier level (1, 2, or 3)\n",
        "- Multisource (text) - MONY code (Y, N, or O)\n",
        "\n",
        "Sample data:\n",
        "(1500, 123456778, 123456, 1, Y)\n",
        "(1500, 923456778, 623456, 2, O)\n",
        "(1500, 923456778, 34523456, 2, N)\n",
        "(1500, 923456778, 7823456, 3, O)\n",
        "(1500, 923456778, 564523456, 3, N)\n",
        "\"\"\"\n",
        "\n",
        "# Sample formulary data (for local lookups)\n",
        "formulary_data = [\n",
        "    (\"1500\", \"123456778\", \"123456\", \"1\", \"Y\"),\n",
        "    (\"1500\", \"923456778\", \"623456\", \"2\", \"O\"),\n",
        "    (\"1500\", \"923456778\", \"34523456\", \"2\", \"N\"),\n",
        "    (\"1500\", \"923456778\", \"7823456\", \"3\", \"O\"),\n",
        "    (\"1500\", \"923456778\", \"564523456\", \"3\", \"N\")\n",
        "]\n",
        "\n",
        "# Load scenarios from JSON file\n",
        "try:\n",
        "    with open('scenarios.json', 'r') as f:\n",
        "        scenarios = json.load(f)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: scenarios.json file not found. Please run Phase 1 first.\")\n",
        "    exit(1)\n",
        "\n",
        "# Create a model instance\n",
        "model = genai.GenerativeModel(\n",
        "    model_name=\"models/gemini-1.5-pro-latest\",  # Use an appropriate model\n",
        "    generation_config={\n",
        "        \"temperature\": 0.0,  # Zero temperature for deterministic output\n",
        "        \"top_p\": 1.0,\n",
        "        \"top_k\": 1,\n",
        "        \"max_output_tokens\": 8192,\n",
        "    }\n",
        ")\n",
        "\n",
        "def generate_sql_with_batching(scenarios, db_schema, batch_size=3):\n",
        "    \"\"\"Generate SQL queries for scenarios using batching to avoid rate limits\"\"\"\n",
        "\n",
        "    # Create a base prompt that explains what we want to do\n",
        "    base_prompt = f\"\"\"\n",
        "You are a SQL query generator for pharmacy benefit test scenarios.\n",
        "\n",
        "DATABASE SCHEMA:\n",
        "{db_schema}\n",
        "\n",
        "I will provide you with multiple scenarios. For each scenario, generate a SQL query that will find the matching NDC\n",
        "in the formulary_data table.\n",
        "\n",
        "For scenarios that follow this pattern: \"Copay Tier_X_(Y)_Channel_Z DS\"\n",
        "Where:\n",
        "- X is the tier number (1, 2, or 3)\n",
        "- Y is the MONY code (Y, N, or O)\n",
        "- Channel and Z are not relevant for the query\n",
        "\n",
        "The query should check for:\n",
        "1. The Formulary_ID matching the scenario's formulary_id field\n",
        "2. The Tier matching the tier number extracted from the scenario pattern\n",
        "3. The Multisource matching the MONY code extracted from the scenario pattern\n",
        "\n",
        "Format your response exactly as follows, with one SQL query per line:\n",
        "\n",
        "QUERY1: SELECT NDC FROM formulary_data WHERE Formulary_ID = 'formulary_id1' AND Tier = 'tier1' AND Multisource = 'mony1'\n",
        "QUERY2: SELECT NDC FROM formulary_data WHERE Formulary_ID = 'formulary_id2' AND Tier = 'tier2' AND Multisource = 'mony2'\n",
        "...etc.\n",
        "\n",
        "Do not include any explanations or other text, just the SQL queries prefixed by QUERY1:, QUERY2:, etc.\n",
        "\"\"\"\n",
        "\n",
        "    # Process scenarios in batches\n",
        "    updated_scenarios = []\n",
        "\n",
        "    # Create batches\n",
        "    batches = [scenarios[i:i + batch_size] for i in range(0, len(scenarios), batch_size)]\n",
        "\n",
        "    for batch_index, batch in enumerate(batches):\n",
        "        # Add a sleep between batches to avoid rate limits\n",
        "        if batch_index > 0:\n",
        "            sleep_time = 2 + random.uniform(1, 3)  # Random sleep between 3-5 seconds\n",
        "            print(f\"Waiting {sleep_time:.1f} seconds before processing next batch...\")\n",
        "            time.sleep(sleep_time)\n",
        "\n",
        "        print(f\"Processing batch {batch_index+1}/{len(batches)} ({len(batch)} scenarios)...\")\n",
        "\n",
        "        # Build batch prompt\n",
        "        batch_prompt = base_prompt + \"\\n\\nScenarios:\\n\"\n",
        "        for i, scenario in enumerate(batch):\n",
        "            formulary_id = scenario['formulary_id']\n",
        "            scenario_text = scenario['scenario']\n",
        "            batch_prompt += f\"{i+1}. {scenario_text} (Formulary ID: {formulary_id})\\n\"\n",
        "\n",
        "        # Maximum retries for API calls\n",
        "        max_retries = 3\n",
        "        success = False\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                # Call the LLM with the batch\n",
        "                response = model.generate_content(batch_prompt)\n",
        "                response_text = response.text.strip()\n",
        "\n",
        "                # Parse the response\n",
        "                queries = {}\n",
        "                for line in response_text.split('\\n'):\n",
        "                    if line.startswith('QUERY'):\n",
        "                        query_num_str = line.split(':')[0].strip()\n",
        "                        query_num = int(query_num_str.replace('QUERY', ''))\n",
        "                        query_sql = line.split(':', 1)[1].strip()\n",
        "                        queries[query_num] = query_sql\n",
        "\n",
        "                success = True\n",
        "                break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Attempt {attempt+1}/{max_retries} failed: {e}\")\n",
        "                if attempt < max_retries - 1:\n",
        "                    sleep_time = 5 * (attempt + 1)  # Exponential backoff\n",
        "                    print(f\"Retrying in {sleep_time} seconds...\")\n",
        "                    time.sleep(sleep_time)\n",
        "\n",
        "        # If all API calls failed, use regex fallback for the batch\n",
        "        if not success:\n",
        "            print(\"All API attempts failed. Using regex fallback for this batch.\")\n",
        "            queries = {}\n",
        "            for i, scenario in enumerate(batch):\n",
        "                pattern = r'Copay Tier_(\\d+)_\\(([A-Z])\\)'\n",
        "                match = re.search(pattern, scenario['scenario'])\n",
        "                if match:\n",
        "                    tier = match.group(1)\n",
        "                    mony = match.group(2)\n",
        "                    formulary_id = scenario['formulary_id']\n",
        "                    queries[i+1] = f\"SELECT NDC FROM formulary_data WHERE Formulary_ID = '{formulary_id}' AND Tier = '{tier}' AND Multisource = '{mony}'\"\n",
        "                else:\n",
        "                    queries[i+1] = \"ERROR: Could not parse scenario\"\n",
        "\n",
        "        # Process each scenario in the batch with the returned queries\n",
        "        for i, scenario in enumerate(batch):\n",
        "            query_num = i + 1\n",
        "\n",
        "            if query_num in queries:\n",
        "                sql_query = queries[query_num]\n",
        "                scenario[\"sql_query\"] = sql_query\n",
        "\n",
        "                # Extract parameters from the SQL query for NDC lookup\n",
        "                try:\n",
        "                    formulary_match = re.search(r\"Formulary_ID\\s*=\\s*'([^']+)'\", sql_query)\n",
        "                    tier_match = re.search(r\"Tier\\s*=\\s*'([^']+)'\", sql_query)\n",
        "                    multisource_match = re.search(r\"Multisource\\s*=\\s*'([^']+)'\", sql_query)\n",
        "\n",
        "                    if formulary_match and tier_match and multisource_match:\n",
        "                        sql_formulary_id = formulary_match.group(1)\n",
        "                        sql_tier = tier_match.group(1)\n",
        "                        sql_multisource = multisource_match.group(1)\n",
        "\n",
        "                        # Simulate database lookup with sample data\n",
        "                        ndc = None\n",
        "                        for row in formulary_data:\n",
        "                            if (row[0] == sql_formulary_id and\n",
        "                                row[3] == sql_tier and\n",
        "                                row[4] == sql_multisource):\n",
        "                                ndc = row[2]\n",
        "                                break\n",
        "\n",
        "                        scenario[\"ndc\"] = ndc if ndc else \"No matching NDC found\"\n",
        "                    else:\n",
        "                        scenario[\"ndc\"] = \"Error: Could not parse SQL parameters\"\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error extracting parameters from SQL for scenario '{scenario['scenario']}': {e}\")\n",
        "                    scenario[\"ndc\"] = f\"Error: {str(e)}\"\n",
        "            else:\n",
        "                scenario[\"sql_query\"] = \"Error: No SQL generated for this scenario\"\n",
        "                scenario[\"ndc\"] = \"Error: No SQL query available\"\n",
        "\n",
        "            updated_scenarios.append(scenario)\n",
        "\n",
        "    return updated_scenarios\n",
        "\n",
        "# Use the alternative approach with batching\n",
        "enriched_scenarios = generate_sql_with_batching(scenarios, formulary_schema, batch_size=5)\n",
        "\n",
        "# Print a few scenarios for verification\n",
        "print(json.dumps(enriched_scenarios[:2], indent=2))\n",
        "\n",
        "# Save to file\n",
        "with open('scenarios_with_ndc.json', 'w') as f:\n",
        "    json.dump(enriched_scenarios, f, indent=2)\n",
        "print(f\"Updated {len(enriched_scenarios)} scenarios saved to scenarios_with_ndc.json\")\n",
        "\n",
        "# Alternative approach: Generate all SQL queries locally with regex\n",
        "# This can be used as a fallback if API limits are too restrictive\n",
        "def generate_sql_locally(scenarios):\n",
        "    \"\"\"Generate SQL queries using regex pattern matching without LLM\"\"\"\n",
        "    updated_scenarios = []\n",
        "\n",
        "    for scenario in scenarios:\n",
        "        scenario_string = scenario['scenario']\n",
        "        formulary_id = scenario['formulary_id']\n",
        "\n",
        "        # Extract tier and MONY code using regex\n",
        "        pattern = r'Copay Tier_(\\d+)_\\(([A-Z])\\)'\n",
        "        match = re.search(pattern, scenario_string)\n",
        "\n",
        "        if match:\n",
        "            tier = match.group(1)\n",
        "            mony = match.group(2)\n",
        "            sql_query = f\"SELECT NDC FROM formulary_data WHERE Formulary_ID = '{formulary_id}' AND Tier = '{tier}' AND Multisource = '{mony}'\"\n",
        "\n",
        "            # Add the SQL query to the scenario\n",
        "            scenario[\"sql_query\"] = sql_query\n",
        "\n",
        "            # Simulate database lookup with sample data\n",
        "            ndc = None\n",
        "            for row in formulary_data:\n",
        "                if (row[0] == formulary_id and row[3] == tier and row[4] == mony):\n",
        "                    ndc = row[2]\n",
        "                    break\n",
        "\n",
        "            scenario[\"ndc\"] = ndc if ndc else \"No matching NDC found\"\n",
        "        else:\n",
        "            scenario[\"sql_query\"] = \"Error: Could not generate SQL query\"\n",
        "            scenario[\"ndc\"] = \"Error: Could not parse tier and MONY\"\n",
        "\n",
        "        updated_scenarios.append(scenario)\n",
        "\n",
        "    return updated_scenarios\n",
        "\n",
        "# If you want to use the regex-only approach instead (no API calls):\n",
        "# enriched_scenarios = generate_sql_locally(scenarios)\n",
        "# with open('scenarios_with_ndc_local.json', 'w') as f:\n",
        "#     json.dump(enriched_scenarios, f, indent=2)\n",
        "# print(f\"Updated {len(enriched_scenarios)} scenarios saved locally to scenarios_with_ndc_local.json\")\n",
        "\n",
        "# In a real-world implementation, you would replace the sample data lookup\n",
        "# with an actual database connection:\n",
        "\"\"\"\n",
        "# Example with a real database connection\n",
        "import sqlite3\n",
        "\n",
        "def find_ndc_with_real_db(sql_query):\n",
        "    conn = sqlite3.connect('formulary.db')\n",
        "    cursor = conn.cursor()\n",
        "    try:\n",
        "        cursor.execute(sql_query)\n",
        "        result = cursor.fetchone()\n",
        "        if result:\n",
        "            return result[0]  # Return the NDC\n",
        "        else:\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Database error: {e}\")\n",
        "        return None\n",
        "    finally:\n",
        "        conn.close()\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 576
        },
        "id": "PylXRHQAw8fA",
        "outputId": "32417893-5b98-4d3b-fd94-aa9686a81f6a"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing batch 1/2 (5 scenarios)...\n",
            "Waiting 4.7 seconds before processing next batch...\n",
            "Processing batch 2/2 (5 scenarios)...\n",
            "[\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_1_(Y)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$12.5- Flat Dollar Copay\",\n",
            "    \"sql_query\": \"SELECT NDC FROM formulary_data WHERE Formulary_ID = '1500' AND Tier = '1' AND Multisource = 'Y'\",\n",
            "    \"ndc\": \"123456\"\n",
            "  },\n",
            "  {\n",
            "    \"plan_id\": \"2162LWTP01\",\n",
            "    \"formulary_id\": \"1500\",\n",
            "    \"testbed\": \"PP_Flat_Copay\",\n",
            "    \"scenario\": \"Copay Tier_2_(N)_Mail_90 DS\",\n",
            "    \"verification\": \"Verify_$62.5- Flat Dollar Copay\",\n",
            "    \"sql_query\": \"SELECT NDC FROM formulary_data WHERE Formulary_ID = '1500' AND Tier = '2' AND Multisource = 'N'\",\n",
            "    \"ndc\": \"34523456\"\n",
            "  }\n",
            "]\n",
            "Updated 10 scenarios saved to scenarios_with_ndc.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Example with a real database connection\\nimport sqlite3\\n\\ndef find_ndc_with_real_db(sql_query):\\n    conn = sqlite3.connect(\\'formulary.db\\')\\n    cursor = conn.cursor()\\n    try:\\n        cursor.execute(sql_query)\\n        result = cursor.fetchone()\\n        if result:\\n            return result[0]  # Return the NDC\\n        else:\\n            return None\\n    except Exception as e:\\n        print(f\"Database error: {e}\")\\n        return None\\n    finally:\\n        conn.close()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yk0yKwRKxXaU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}